:source-highlighter: pygments
:toc: left 
:toc-title: Codes Index
:toclevels: 10

= Basic codes for Digital Image Processing
João Marcos Costa <jmcosta944@gmail.com>
== Implementing image processing theory with OpenCV(C++), by João Marcos Costa
This portfolio is being built to report all knowledge-acquiring process along the Digital Image Processing course given at Federal University of Rio Grande do Norte (UFRN), Brazil. If there is some specific information needed to understand the codes (either documentation or image processing theory), it will be given. This site will be upgraded along the course. 

:numbered:
== Exchanging regions, negative images and converting RGB model to greyscale (only shades of grey)

The first part is pretty simple: we'll see how to acess a pixel's value and manipulate an image's region
(tranfering, changing, copying...). 

=== Exchange a region (randomly way)
We index the regions from left to right and top to bottom, as it is shown below.

image::cheregions.jpg[title="Indexed regions"]

[[app-listing]]
[source, cpp]
.random.cpp
----
include::random.cpp[]
----

Executing the algorithm, we can get:

image::changed.jpg[title="Random exchanging"]


=== Exchange a region (letting the user choose the order and number of regions)
Let's see what we get from picking 6 regions, 2 verticals * 3 horizontals and the order 5,0,1,2,4,3.

image::che.jpg[title="Original"]

image::result.jpg[title="Order: 5,0,1,2,4,3. 3 verticals and 2 horizontals"]


[[app-listing]]
[source, cpp]
.superchangeregions.cpp
----
include::superchangeregions.cpp[]
----

=== Getting a negative image

A pixel's negative is the difference between the pixel's value and 255 (maximum value). It works for the RGB model and greyscale as well. Basically, you change the current value by _how many shades you need for 255_.  Example: +
Pixel value is: 100 +
Negative is : 255-100=155 +

[[app-listing]]
[source, cpp]
.negative.cpp
----
include::negative.cpp[]
----
This code apllies the algorithm in greyscale, and to do for RGB model, you need to apply the algorithm into each layer (R,G and B). Remembering that a colored image is an 3D matrix, and a greyscale one is 2D.

Let's see the result for the half of image:

image::hannibal.jpg[title="Original"]

image::negative.jpg[title="Negative (left 	half)"]



=== RGB to Greyscale

This conversion is based on the human eye sensibility for primary colors: Red, Green and Blue. So, you'll need to get the red, blue and green values, take a part of them and sum those parts. The parts are:
30% from Red + 59% from Green + 11% from Blue = tone of grey

[[app-listing]]
[source, cpp]
.rgbtogrey.cpp
----
include::rgbtogrey.cpp[]
----
image::louvre.jpg[title="Original"]

image::rgbtogrey.jpg[title="RGB to Greyscale"]

:numbered:

== Identifying, counting and labeling regions (using the same algorithm)

=== Seedfill 

Seedfill algorithm labels regions of a certain color in a background differently colored. Our examples are pretty simple: white (shade of grey: 255) bubbles in a black background (shade of gray: 0). Before I forget, _seedfill_ and _floodfill_ are different names for the same algorithm.

[[app-listing]]
[source, cpp]
.seedfill.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <stack>
using namespace std;
using namespace cv;

void seedfill (Mat &image, CvPoint p, int label, int color=255){ //color is an optional parameter
	stack<CvPoint> pixel_stack;
	pixel_stack.push(p);
    image.at<uchar>(p)=label;
	CvPoint aux,current;
	while(!pixel_stack.empty()){
		current=pixel_stack.top();
		pixel_stack.pop();
		
		if(image.at<uchar>(current.y+1,current.x)==color){
		aux.y=current.y+1;
		aux.x=current.x;
		image.at<uchar>(current.y+1,current.x)=label;
		pixel_stack.push(aux);}		
		
		if(image.at<uchar>(current.y,current.x+1)==color){
		aux.y=current.y;
		aux.x=current.x+1;
		image.at<uchar>(current.y,current.x+1)=label;
		pixel_stack.push(aux);}
		
		if(image.at<uchar>(current.y-1,current.x)==color){
		aux.y=current.y-1;
		aux.x=current.x;		
		image.at<uchar>(current.y-1,current.x)=label;
		pixel_stack.push(aux);}
		
		if(image.at<uchar>(current.y,current.x-1)==color) {
		aux.y=current.y;
		aux.x=current.x-1;
		image.at<uchar>(current.y,current.x-1)=label;
		pixel_stack.push(aux);}
		


	}
}
----

=== Seedfill implementation

[[app-listing]]
[source, cpp]
.implementation.cpp
----
int main(int argc, char** argv){
  Mat image;
  int width, height;
  int label;

  CvPoint p;
  
  image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);

  if(!image.data){
    std::cout << "imagem  was not correctly loaded \n";
    return(-1);
  }
  
  width=image.cols;
  height=image.rows;
  p.x=0;
  p.y=0;
  label=0;


  for(int i=1;i<height-1; i++){
    for(int j=1;j<width-1; j++){
      if(image.at<uchar>(i,j) == 255){
		label++;
		p.x=j;
		p.y=i;
		seedfill(image,p,label);
	  }
	}
  }
}
----

image::bubbles.png[title="Bubbles"]

image::labeled_bubbles.png[title="Labeled bubbles"]

=== What if I have more than 255 regions at my picture?

Well, Seedfill labels a white regions with the current label. What does it mean? It means that a white (255) region becomes 45 (a "darker" shade of grey) if the algorithm has already counted 45 white regions at the image. But the maximum tone is 255, so we can't have a "whiter" white. I have a tip for people who face such problem: convert the label value, wich is represented in _decimal base_ to an 6 algarism number in _hexadecimal base_. After this, you will convert your hexadecimal number into an RGB value. The first pair of digits will be used for red color, the middle pair for blue color, and the third pair for green color. +
Example: +
[%hardbreaks]
Label: 55671 (decimal)
[%hardbreaks]
Hexadecimal: D977 (since we need 6 digits, we'll call it "00D977")
[%hardbreaks]
RGB=(0,217,119)
[%hardbreaks]
00(hexadecimal) equals to 0 (decimal)
[%hardbreaks]
[%hardbreaks]
D9(hexadecimal) equals to 217 (decimal)
[%hardbreaks]
77(hexadecimal) equals to 119 (decimal)

So, "00" for red, "D9" for blue and "77" for green. Doing this version of "pseudo color", we will identify the white labeled regions by (pseudo)colored patterns, instead of a darker shade of grey (as we did before).

=== Identifying regions with holes

This code is a bit more rough to understand...First of all, we need to cut off the border touching regions, because you can't know if the region has another not-shown holes. Didn't get it? Imagine this: you are taking a picture of a way too big carpet, and this picture shows only a part of it. The border-touching bubbles may or may not have a hole, and you don't know it for sure because you didn't capture the complete bubble. Let me put this in another way: by taking the photo, may have taken a picture of a peculiar bubble with a full white half and another hollowed half. Since the picture only shows the full white half, you think the bubble is completely white, BUT IT IS NOT! After cutting those tricky bubbles, we need to use seedfill to label the background with a different color of the holes, wich are, at first place, all black. After this, we indentify (and delete, if necessary) the hollowed bubbles.

image::noborders.png[title="Original image after removing the border-bubbles"]

image::holes_and_no_borders.png[title="Identified hollowed regions"]

Needing the codes? Here we go...

[[app-listing]]
[source, cpp]
.Cutting borders off
----

Mat remove_border_regions(Mat original_image){ 

Mat image; //image is a copy
original_image.copyTo(image);
CvPoint p;
int label=0,local_label;
for(int i=1; i<image.rows-1; i++){
    for(int j=1; j<image.cols-1; j++){
      if(image.at<uchar>(i,j) == 255){
		label++;
		p.x=j;
		p.y=i;
		seedfill(image,p,label);
	  }
	}
  }

//upper-side border
for(int i=0;i<image.cols;i++){
	if(image.at<uchar>(0,i)>0){
		
		local_label=image.at<uchar>(0,i);
		
		for(int i=0; i<image.rows; i++){
    		for(int j=0; j<image.cols; j++){
     			 if(image.at<uchar>(i,j) == local_label){
					image.at<uchar>(i,j)=0;
}
}
}
}
}    
//bottom-side border
for(int i=0;i<image.cols;i++){
	if(image.at<uchar>(image.rows-1,i)>0){
		
		local_label=image.at<uchar>(image.rows-1,i);
		
		for(int i=0; i<image.rows; i++){
    		for(int j=0; j<image.cols; j++){
     			 if(image.at<uchar>(i,j) == local_label){
					image.at<uchar>(i,j)=0;
}
}
}
}
}  
//left-side border
for(int i=0;i<image.rows;i++){
	if(image.at<uchar>(i,0)>0){
		
		local_label=image.at<uchar>(i,0);
		
		for(int i=0; i<image.rows; i++){
    		for(int j=0; j<image.cols; j++){
     			 if(image.at<uchar>(i,j) == local_label){
					image.at<uchar>(i,j)=0;
}
}
}
}
} 
//right-side border
for(int i=0;i<image.rows;i++){
	if(image.at<uchar>(i,image.cols-1)>0){
		
		local_label=image.at<uchar>(i,image.cols-1);
		
		for(int i=0; i<image.rows; i++){
    		for(int j=0; j<image.cols; j++){
     			 if(image.at<uchar>(i,j) == local_label){
					image.at<uchar>(i,j)=0;
}
}
}
}
} 
//turning regions back to the original shade of gray (usually white)
for(int i=0; i<image.rows; i++){
    for(int j=0; j<image.cols; j++){
      if(image.at<uchar>(i,j)!=0)image.at<uchar>(i,j)=255; //if labeled, turn to white
}
}
return image;

}

----

[[app-listing]]
[source, cpp]
.Hello holes!
----

Mat identify_regions_with_holes(Mat original_image){ //should be used on the UNLABELED image

Mat image; //image is a copy 
original_image.copyTo(image);
CvPoint background_seed;
background_seed.x=1;
background_seed.y=1;

CvPoint p;
int label=0;
for(int i=1; i<image.rows-1; i++){
    for(int j=1; j<image.cols-1; j++){
      if(image.at<uchar>(i,j) == 255){
		label++;
		p.x=j;
		p.y=i;
		seedfill(image,p,label);
}
}
}

//remember that 'image' is already labeled

for(int i=1; i<image.rows-1; i++){
    for(int j=1; j<image.cols-1; j++){
    	image.at<uchar>(i,j)++;
}
}

seedfill(image,background_seed,255,1); //little trick for turning background into white
bool identifying_helper=1;

for(int i=1; i<image.rows-1; i++){
    for(int j=1; j<image.cols-1; j++){
 		if(image.at<uchar>(i,j)==1){ //since holes are (now) labeled with "1"
 			int sum=0,counter=0,label_to_change;
 			if(image.at<uchar>(i+1,j)!=1){
 			counter++;
 			sum+=image.at<uchar>(i+1,j);
 			}
 			if(image.at<uchar>(i,j+1)!=1){
 			counter++;
 			sum+=image.at<uchar>(i,j+1);	
 			}
 			if(image.at<uchar>(i-1,j)!=1){
 			counter++;
 			sum+=image.at<uchar>(i-1,j);	
 			}
 			if(image.at<uchar>(i,j-1)!=1){
 			counter++;
 			sum+=image.at<uchar>(i,j-1);	
 			}
			if(counter>0){
				label_to_change=sum/counter;
				for(int i=1; i<image.rows-1; i++){
    				for(int j=1; j<image.cols-1; j++){
     			 		if(image.at<uchar>(i,j) == label_to_change){
						   identifying_helper= !identifying_helper;
						   image.at<uchar>(i,j)=label+2+label*identifying_helper; 
							}
							}
							}
			} 		
 			} 		 
}
}
seedfill(image,background_seed,0,255); //background returns to black

for(int i=0; i<image.rows; i++){
    for(int j=0; j<image.cols; j++){
    	if(image.at<uchar>(i,j)>1 && image.at<uchar>(i,j)<=label){
		   image.at<uchar>(i,j)=255; //labeled regions return to white
		}
		}
		}
	return image;
}

----

To return those images through new image files, just run:

[[app-listing]]
[source, cpp]
----

int main(int argc, char** argv){
  Mat image;
  int width, height;
  int label;

  CvPoint p;
  
  image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);

  if(!image.data){
    std::cout << "imagem  was not correctly loaded \n";
    return(-1);
  }
  
  width=image.cols;
  height=image.rows;
  p.x=0;
  p.y=0;
  label=0;


  for(int i=1;i<height-1; i++){
    for(int j=1;j<width-1; j++){
      if(image.at<uchar>(i,j) == 255){
		label++;
		p.x=j;
		p.y=i;
		seedfill(image,p,label);
	  }
	}
  }

imwrite("labeled.png",image);
imwrite("noborders.png",remove_border_regions(image));
imwrite("holes_and_no_borders.png",identify_regions_with_holes(remove_border_regions(image)));
cout<<"label:"<<label;

}
----

:numbered:

== Histogram manipulation

Given an image, there are two quite important informations about it: what colors are there and how many times they appear? There is an array to store this data, and it is called _histogram_. Being more specicif: the k-element represents the k-tone of a color and its value represents how many pixels have such tone.
[%hardbreaks]
Example: histogram[k]=341
[%hardbreaks]
- The k-tone of grey, red, blue or green appears 341 times at the image.
[%hardbreaks]
-Remember that an histogram can represent data from a specific row or column as well, not only the whole image.

=== Calculating and exposing colored image's histogram

This first histogram code works for a camera connected to your computer getting colored frames

[[app-listing]]
[source, cpp]
.histogramrgb.cpp
----
include::histogramrgb.cpp[]
----

image::rgbhist.jpg[title="Result"]

NOTE: The histogram graphics are on the top-left corner. They are tiny because the photo was too big.
=== Equalizing histograms 

If you want to increase the image's contrast, there is a series of operations with the histogram to achieve that. First, you calculate the histogram, but this time we need to make it accumulating the previous values. How does it work? Pretty simple: the k-value (histogram[k]) equals to the sum of all the previous values from histogram[0] to histogram[k-1]. After this, we normalize it: multiply each histogram value by the number of colr bands (represented by the _nbins_ variable) - 1 and divide it by the maximum accumulated histogram value (also the last element).

[[app-listing]]
[source, cpp]
.histogram_equalize.cpp
----
include::histogram_equalize.cpp[]
----

image::monroe.jpg[title="Original (lower contrast)"]
image::equalized.jpg[title="Equalized (higher contrast)"]


=== Already-made videos/images instead of using cameras
[%hardbreaks]
If you don't have a camera or webcam but still wants to run those codes, you need to change a few things:

Replace this:
[[app-listing]]
[source, cpp]
----

VideoCapture cap(0);

----

By this:
[[app-listing]]
[source, cpp]
----

VideoCapture cap(argv[1]); //first option

VideoCapture cap("filename.extension"); // second option
----

And remove this:

[[app-listing]]
[source, cpp]
----
  if(!cap.isOpened()){
    cout << "video not loaded";
    return -1;
  }
----

Now, if you have chosen the first opion, do this on your linux terminal to compile and execute the code:

----
$ make histogram_code
$./histogram_code filename.extension
----
NOTE: for dummies : use "make" in the same directory as the .cpp code you want to compile/execute

=== Motion detector based on histogram comparision

This technique is based on comparing two histogram: the current one and the last captured one. If they are way too different, we assume that a moviment has occurred. Else, we assume that nothing has happened. Also, the user should provide a limit for this difference. 

[[app-listing]]
[source, cpp]
.Motion detector
----
include::motion.cpp[]
----

There is also a built-in function from OpenCV to compare histograms, but they let the program a bit slower.
The function is _compareHist(histogram1,histogram2,mode)_. 
See link: http://docs.opencv.org/2.4/modules/imgproc/doc/histograms.html?highlight=comparehist#comparehist[OpenCV documentation] for more details about _compareHist_.

:numbered:

== Spatial filters

Spatial filtering is based on two elements: an image and a kernel. Kernels are matrixes with specific elements to detect or emphasize properties from the original image. The results are obtained by convolving an image and a kernel. 

[[app-listing]]
[source, cpp]
.Kernels
----
  float media[] = {1,1,1,
				   1,1,1,
				   1,1,1};
  
  float gauss[] = {1,2,1,
				   2,4,2,
				   1,2,1};
  
  float vertical[]={-1,0,1,
					-2,0,2,
					-1,0,1};
  
  float horizontal[]={-1,-2,-1,
					   0,0,0,
					   1,2,1};
  
  float laplacian[]={0,-1,0,
					-1,4,-1,
					 0,-1,0};
----


To apply all those kernels (masks,filters) it, we have the code below:

NOTE: Since I have no camera connected, the code works for an specific image. As I have shown above, it is possible to make some changes (I guess they are practically the same) and adjust the code for cameras.

[[app-listing]]
[source, cpp]
.Spatial filters
----
include::spatialfilter.cpp[]
----

=== Media

Provides the arithmetical media of all 9 pixels. Good for reducing noise. The effect is not properly noticed on the example, but maybe with some zoom you'll be able to see it.

image::media_filter_result.jpg[title="Before & After"]

=== Gaussian

The Gaussian filter effect is a soft blur (opposite of contrast). Also good for removing noise.

image::gaussian_filter_result.jpg[title="Before & After"]

=== Horizontal

Highlights horizontal edges.

image::horizontal_filter_result.jpg[title="Before & After"]

=== Vertical

Highlights vertical edges.

image::vertical_filter_result.jpg[title="Before & After"]

=== Laplacian

Sharpening filter for finer edges.

image::laplacian_filter_result.jpg[title="Before & After"]

=== Laplacian & Gaussian

Since gaussian filter removes the noise through blurring, the image quality is better and the laplacian filter won't sharpen the tiny (really tiny) edges given by noise. So, doing this combination consists in "cleaning" the image before sharpening the edges, wich causes a better contrast.

image::lapgauss_filter_result.jpg[title="Before & After"]


image::lapgauss_filter_plus_original_result.jpg[title="Laplacian&Gaussian + Original image"]

:numbered:

== Spatial filters II

=== Tilt Shift effect

There is a special effect from blurring only specific parts of an image, wich makes the "unblurred" part seems like a miniature photo. We can reproduce Tilt Shift effect through the code below, regulating with the trackbars where the blurrings starts (L1 parameter)/stops (L2 parameter) and how intense (D parameter) this blurring is.

[[app-listing]]
[source, cpp]
.Tilt Shift 
----
include::tiltshift.cpp[]
----
image::print.png[title="Using trackbars"]

image::lituania.jpeg[title="Vilnius, Lituania (original)"]

image::tiltshifted_image.jpeg[title="Vilnius, Lituania (tiltshifted)"]


:sectnums!:

:numbered:

== Images at Frequency domain/representation

There are two domains in wich we can representate an image: the first and most common is the spatial one, and the other is frequential. Frequency representation consists in representing an image not by its colors, but using periodic characteristics (noises, tones, etc..). Of course, there is some math involved on the process: we shall use Fourier's transform on its discrete way (DFT). See link: https://en.wikipedia.org/wiki/Discrete_Fourier_transform for more details about DFT and DFFT.

=== Getting image's frequency representation
Here is some code for implementing the transform:

[[app-listing]]
[source, cpp]
.Making the Spectrum
----
void shiftsDFT(Mat& image ){ 
  Mat tmp, A, B, C, D;

  image = image(Rect(0, 0, image.cols & -2, image.rows & -2));
  int cx = image.cols/2;
  int cy = image.rows/2;

  // recombines the transforms's quadrants
  // A B   ->  D C
  // C D       B A
  A = image(Rect(0, 0, cx, cy));
  B = image(Rect(cx, 0, cx, cy));
  C = image(Rect(0, cy, cx, cy));
  D = image(Rect(cx, cy, cx, cy));

  A.copyTo(tmp);  D.copyTo(A);  tmp.copyTo(D);

  C.copyTo(tmp);  B.copyTo(C);  tmp.copyTo(B);
}

Mat MakeSpectrum (Mat &image){ //returns image in frequency domain
  vector<Mat> planes;
  planes.clear();
  Mat padded, complexImage;
  Mat_<float> realInput, zeros;
  int dft_M, dft_N;  
  dft_M = getOptimalDFTSize(image.rows);
  dft_N = getOptimalDFTSize(image.cols);
  copyMakeBorder(image, padded, 0,
                 dft_M - image.rows, 0,
                 dft_N - image.cols,
                 BORDER_CONSTANT, Scalar::all(0));

  zeros = Mat_<float>::zeros(padded.size());

  complexImage = Mat(padded.size(), CV_32FC2, Scalar(0));
  realInput = Mat_<float>(padded);
  
  planes.push_back(realInput);
  planes.push_back(zeros);
  merge(planes, complexImage);
  dft(complexImage, complexImage);
  shiftsDFT(complexImage);
  return complexImage;
}

----

To see the results, we need to put the data into logarithmic scale:

[[app-listing]]
[source, cpp]
.Showing Spectrum
----
void ShowSpectrum(Mat &Im, string s="Spectrum"){ 
  Mat ImS;
  vector<Mat> planes;
  planes.clear();
  Im.copyTo(ImS);
  split(ImS,planes);
  planes[0] += Scalar::all(1); // to avoid log(0)
  log(planes[0],planes[0]);
  normalize(planes[0], planes[0], 0, 1, CV_MINMAX);
  imshow(s,planes[0]);
  waitKey(0);

}
----

image::specsample.png[title="Original and its Spectrum"]

=== Filtering

There are four kinds of filtering I will show you: low-pass, high-pass, band-pass and homomorphical. All those filters select some frequencies and removes the rest of them. The spots closer to the spectrum's center are the lower frequencies, and as long as the distance from the center increases, the frequencies increase as well.

=== Low pass 

Keeps the frequencies lower then an limit frequency given by the user.

[[app-listing]]
[source, cpp]
.Low pass
----
Mat MakeLowPass(Mat &Im, float RADIUS){
  Mat filter=Im.clone();
  int dft_M = getOptimalDFTSize(Im.rows);
  int dft_N = getOptimalDFTSize(Im.cols); 
  Mat tmp(dft_M,dft_N,CV_32F);
  for(int i=0; i<dft_M; i++){
    for(int j=0; j<dft_N; j++){
      if((i-dft_M/2)*(i-dft_M/2)+(j-dft_N/2)*(j-dft_N/2) < RADIUS*RADIUS){
        tmp.at<float> (i,j) = 1.0;
      }
      else         tmp.at<float> (i,j) = 0.0;
 
    }
  }
  resize(tmp,tmp,filter.size()); //making sure the filter will have the same size of the input image

  Mat comps[]= {tmp, tmp};
  merge(comps, 2, filter);
  return filter;
}

----

image::lowpass.png[title="Low pass filter"]

image::lowpass.png[title="Low pass filter result"]

=== High pass

Keeps the frequencies higher then an limit frequency given by the user.

[[app-listing]]
[source, cpp]
.High pass
----
Mat MakeHighPass(Mat &Im, float RADIUS){
  Mat filter=Im.clone();
  int dft_M = getOptimalDFTSize(Im.rows);
  int dft_N = getOptimalDFTSize(Im.cols); 
  Mat tmp(dft_M,dft_N,CV_32F);
  for(int i=0; i<dft_M; i++){
    for(int j=0; j<dft_N; j++){
      if((i-dft_M/2)*(i-dft_M/2)+(j-dft_N/2)*(j-dft_N/2) < RADIUS*RADIUS){
        tmp.at<float> (i,j) = 0.0;
      }
      else         tmp.at<float> (i,j) = 1.0;
 
    }
  }
  resize(tmp,tmp,filter.size()); //making sure the filter will have the same size of the input image

  Mat comps[]= {tmp, tmp};
  merge(comps, 2, filter);
  return filter;
}

----
image::highpass.png[title="High pass filter"]

image::highpass2.png[title="High pass filter result"]

=== Band pass

Keeps the frequencies between the two limits given by the user, and discards the rest

[[app-listing]]
[source, cpp]
.Band pass
----
Mat MakeBandPass(Mat &Im, float MAX_RADIUS, float MIN_RADIUS){
  Mat filter=Im.clone();
  int dft_M = getOptimalDFTSize(Im.rows);
  int dft_N = getOptimalDFTSize(Im.cols); 
  Mat tmp(dft_M,dft_N,CV_32F);
  for(int i=0; i<dft_M; i++){
    for(int j=0; j<dft_N; j++){
      if((i-dft_M/2)*(i-dft_M/2)+(j-dft_N/2)*(j-dft_N/2) < MAX_RADIUS*MAX_RADIUS
        &&(i-dft_M/2)*(i-dft_M/2)+(j-dft_N/2)*(j-dft_N/2) > MIN_RADIUS*MIN_RADIUS){
        tmp.at<float> (i,j) = 1.0;
      }
      else         tmp.at<float> (i,j) = 0.0;  
    }
  }
  resize(tmp,tmp,filter.size()); //making sure the filter will have the same size of the input image

  Mat comps[]= {tmp, tmp};
  merge(comps, 2, filter);
  return filter;
}
----

image::bandpass.png[title="Band pass filter"]

image::bandpass2.png[title="Band pass filter result"]

=== Homomorphical filter

We can use Homomorphical filter for giving a better luminosity distribution for the scene. For such, we increase high frequencies and decrease the lower ones.


[[app-listing]]
[source, cpp]
.Homomorphical filter
----
Mat MakeHomomorphical(Mat &Im,float GAMMA_H, float GAMMA_L, float c, float RADIUS){
  Mat filter=Im.clone();
  int dft_M = getOptimalDFTSize(Im.rows);
  int dft_N = getOptimalDFTSize(Im.cols); 
  Mat tmp(dft_M,dft_N,CV_32F);
  float D0=RADIUS*RADIUS,  D;
  for(int i=0; i<dft_M; i++){
    for(int j=0; j<dft_N; j++){
        D=(i-dft_M/2)*(i-dft_M/2)+(j-dft_N/2)*(j-dft_N/2);
        
        tmp.at<float> (i,j)= (GAMMA_H - GAMMA_L)*(1-exp(-c*(D/D0)))+GAMMA_L;
 
    }
  }
  resize(tmp,tmp,filter.size()); //making sure the filter will have the same size of the input image
  Mat comps[]= {tmp, tmp};
  merge(comps, 2, filter);
  return filter;
}

Mat getBack(Mat &Im){ //frequency to space for exhibition
  Mat ImS;
  vector<Mat> planes;
  Im.copyTo(ImS);
  shiftsDFT(ImS);
  idft(ImS,ImS);
  planes.clear();
  split(ImS,planes);
  normalize(planes[0], planes[0], 0, 1, CV_MINMAX);
  return planes[0];
}


int main(int argc , char** argv){
  Mat complexImage;
  Mat filter;
  Mat image;
  vector<Mat> planes;
  image=imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
  Mat ln_image;
  ln_image = Mat_<float>(image);
  normalize(ln_image, ln_image, 0, 1, CV_MINMAX);

  ln_image+=Scalar::all(1);  
  log(ln_image,ln_image);
  complexImage=MakeSpectrum(ln_image);


  float YH,YL,c,D0;
  cin>>YH>>YL>>c>>D0;

  filter=MakeHomomorphical(complexImage,YH,YL,c,D0);
 
 
  mulSpectrums(complexImage,filter,complexImage,0);
  Mat final=getBack(complexImage);
  exp(final,final);
  normalize(final,final,0,1,CV_MINMAX);
  imshow("f",final);
  imshow("original",image);
  waitKey(0);

----

image::hmm.png[title="Homomorphical filter"]

image::hmm2.png[title="Homomorphical filter result"]

=== Noise

If you take a look back into the low/high pass filters, you'll see some tiny periodic circles as a result of filtering. We call that noise (Moiré pattern), and we can insert artifical noise in any image we want...

[[app-listing]]
[source, cpp]
.Artificial noise
----

Mat InsertNoise(Mat &Im, float freq, float gain){//returns image in frequency domain
  vector<Mat> planes;
  planes.clear();
  Mat ImS;
  Mat padded;
  int dft_M = getOptimalDFTSize(Im.rows);
  int dft_N = getOptimalDFTSize(Im.cols); 
  copyMakeBorder(Im, padded, 0,
                 dft_M - Im.rows, 0,
                 dft_N - Im.cols,
                 BORDER_CONSTANT, Scalar::all(0));
  ImS = Mat(padded.size(), CV_32FC2, Scalar(0));  
  MakeSpectrum(Im).copyTo(ImS);
  split(ImS,planes);
  float mean;
  mean = abs(planes[0].at<float>(dft_M/2,dft_N/2));

  planes[0].at<float>(dft_M/2 +freq, dft_N/2 +freq) +=gain*mean;
  planes[1].at<float>(dft_M/2 +freq, dft_N/2 +freq) +=gain*mean;
  planes[0].at<float>(dft_M/2 -freq, dft_N/2 -freq) =planes[0].at<float>(dft_M/2 +freq, dft_N/2 +freq);
  planes[1].at<float>(dft_M/2 -freq, dft_N/2 -freq) =-planes[1].at<float>(dft_M/2 +freq, dft_N/2 +freq);

  merge(planes,ImS);
  return ImS;

}

----

image::noise.png[title="Periodic noise"]

== About the author

João Marcos Costa, majoring in Electrical Engineering at the Federal University of Rio Grande do Norte (UFRN), Brazil. Managing areas as programming (C/C++,Python and Scilab), Digital Image Processing, and interested in learning programming to Android platform, Electronics (Digital and analogical), such as Social Studies: philosophy, pedagogical methods, and politics (marxist analysis).